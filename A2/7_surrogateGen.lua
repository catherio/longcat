-------------------------------------------------------------------
-- Surrogate data generation
--
-- This script creates a new dataset, out of the unlabeled data,
-- based on the techniques in Dosovitskiy et al. Surrogate
-- data classes are generated by extracting a patch from an
-- image and generating transformed samples from it.
--
-- LongCat: Catherine Olsson, Long Sha, Kevin Brown
--------------------------------------------------------------------
require 'torch'
require 'image'

-------------------------------------------------------------------
--
-- parse command line arguments
if not opt then
   print '==> processing options'
   cmd = torch.CmdLine()
   cmd:text()
   cmd:text('STL-10 Dataset Preprocessing')
   cmd:text()
   cmd:text('Options:')
   cmd:option('-size', 'small', 'how many unlabeled samples do we load: small | full')
   cmd:option('-datafolder', 'dataset', 'subdirectory where dataset is saved')
   cmd:option('-nclasses', 20, 'how many surrogate classes do we create, default = 5')
   cmd:option('-nexemplars', 100, 'how many exemplars in each surrogate class, default = 10')
   cmd:text()
   opt = cmd:parse(arg or {})
end

-------------------------------------------------------------------
--

print '==> loading raw dataset'
input_filename = opt.datafolder .. '/unlabel.dat'
loaded = torch.load(input_filename, 'ascii')

if opt.size == 'full' then
   print '==> using full unlabeled data, recommend use only for final testing'
   unsize = 100000
elseif opt.size == 'small' then
   print '==> using reduced unlabeled data, for fast experiments'
   unsize = 10000
end

loaded.X = loaded.X[{{},{1,unsize}}]

inputData = {
    data = loaded.X:transpose(1,2):reshape(unsize,3,96,96):transpose(3,4),
    size = function() return unsize end
}
-- this is important to make image processing work!
-- We can keep the data as double here, change the preprocessing
inputData.data = inputData.data:double() / 255

-------------------------------------------------------------------
--
-- Set up the surrogate generation pipeline

function wrapZeroOne(x)
-- for preprocessing in hue space
   if x < 0 then
	  return 1 - x
   elseif x > 1 then
	  return x - 1
   end
end

function makeExemplars(im, fullres, smallres, nExemplars)
-- the real heart of it. Creates n exemplars using a patch from the
-- provided image, and many transformations applied

    mx = (smallres/2)*math.sqrt(2) -- needs to be centered further in,
        -- so that rotation doesn't lead to black spaces forming

    -- choose center of seed patch
    xseed = math.random(mx, fullres-mx)
    yseed = math.random(mx, fullres-mx)
        -- note: math.random with two args gives integers (useful
	    -- for pixel positions) whereas without args it gives
	    -- continuous numbers from 0 to 1

    -- seed = image.crop(im, xseed-smallres/2, yseed-smallres/2, xseed+smallres/2, yseed+smallres/2)
    -- itorch.image(seed) -- uncomment to visualize in notebook

    -- make modifications to the image
    exemplars = torch.DoubleTensor(nExemplars, 3, smallres, smallres)
    for i = 1,nExemplars do
        -- scaling: 0.7 to 1.4
        toscale = fullres * (math.random()*0.7 + 0.7);
        temp = image.scale(im, toscale, toscale)

        -- rotation: up to 20 degrees, i.e 0.35 radians
        torotate = math.random()*0.7 - 0.35
        temp = image.rotate(im, torotate)

        -- convert to HSV for the next transformations
        temp = image.rgb2hsv(temp)

        -- contrast 1: not implemented, requires PCA

        -- contrast 2: convert to HSV; raise S and V to a power between 0.25 and 4 (edit: 3);
        -- multiply by 0.7 through 1.4; add -0.1 to 0.1
        topow = math.random() * 2.75 + 0.25
        tomul = math.random() * 0.7 + 0.7
        toadd = math.random() * 0.2 - 0.1
        temp[{2,{},{}}] = torch.mul(torch.pow(temp[{2,{},{}}], topow), tomul) + toadd

        topow = math.random() * 2.75 + 0.25
        tomul = math.random() * 0.7 + 0.7
        toadd = math.random() * 0.2 - 0.1
        temp[{3,{},{}}] = torch.mul(torch.pow(temp[{3,{},{}}], topow), tomul) + toadd

        -- hue: add a value between -0.1 and 0.1 to the hue
        toadd = math.random() * 0.2 - 0.1
        temp[{1,{},{}}] = temp[{1,{},{}}] + toadd
        temp[{1,{},{}}]:apply(wrapZeroOne)

        -- convert back to RGB
        temp = image.hsv2rgb(temp)

        -- translation: within 0.2 of the patch size
        xpatch = torch.round(xseed + (math.random()*0.4 - 0.2)*smallres)
        ypatch = torch.round(yseed + (math.random()*0.4 - 0.2)*smallres)

        exemplars[{{i}, {}, {}, {}}] = image.crop(temp, xpatch-smallres/2, ypatch-smallres/2, xpatch+smallres/2, ypatch+smallres/2)
    end

    return exemplars
end


-------------------------------------------------------------------
--
-- Use that function to create the new dataset!
nClasses = opt.nclasses
nExemplars = opt.nexemplars

fullres = 96
smallres = 32

newData = {
    data = torch.DoubleTensor(nClasses*nExemplars, 3, smallres, smallres),
    labels = torch.DoubleTensor(nClasses*nExemplars),
    size = function() return nClasses*nExemplars end
}

-- parameters controlling when/how time estimates are displayed
local time = sys.clock()
estimateStart = 1; -- make initial estimate at this class
estimateInterval = 20; -- give updates after every nth class

-- do the loop!
print '==> generating surrogate classes'
idx = 1
for class = 1,nClasses do
    -- choose a seed image
    imnum = math.random(1, inputData.size())
    im = inputData.data[{imnum, {}, {}, {}}]

    -- generate patches
    newData.data[{{idx,idx+nExemplars-1}, {}, {}, {}}] = makeExemplars(im, fullres, smallres, nExemplars)

    -- set class labels
    newData.labels[{{idx,idx+nExemplars-1}}] = class
        -- slicing takes one index or list *per dimension*, so need a list of one list

    -- advance the index
    idx = idx + nExemplars

	  -- estimate the total training time
	  if (class == estimateStart) or (class % estimateInterval == 0) then
	  	 timeSoFar = sys.clock() - time
		 print("==> interim time to generate "..class.." surrogate classes (" .. nExemplars .. " images) is "..
				  (os.date("!%X",timeSoFar)))
		 estimate = timeSoFar * (nClasses/class)
		 print("    estimated time for "..nClasses.." surrogate classes (" .. nExemplars*nClasses .." images) is "..
				  (os.date("!%X",estimate)))

		 -- save partial progress while we're here
		 partialname = opt.datafolder .. '/surrogate-partial.dat'
		 torch.save(partialname, newData)
      end
end

-- add shuffling and demean step on newData
for i= 1,3 do
   -- de-mean each channel globally:
   newData.data[{ {},i,{},{} }]:add(-newData.data[{ {},i,{},{} }]:mean())
end

--shuffling
surData = {data=torch.zeros(newData.data:size()),
           labels=torch.zeros(newData.labels:size()),
           size = function() return newData:size() end
}
surshuffle = torch.randperm(newData:size())
for i = 1,newData:size() do
    surData.data[{i,{},{},{}}] = newData.data[{surshuffle[i],{},{},{}}]
    surData.labels[i] = newData.labels[surshuffle[i]]
end

-- save full results
--filename = opt.datafolder .. '/surrogate.dat'
--torch.save(filename, surData,'ascii') --added format so we can re-load data
