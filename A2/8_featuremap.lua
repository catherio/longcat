
-------------------------------------------------------------------
-- Generate feature map
--
-- This script creates new train and test data set so they become
-- feature maps, which are the output of the model trained on surrogate
-- dataset, applied on each patch.
-- The model model_sur.net should be already trained by surrogate dataset
-- Based on the techniques in Dosovitskiy et al. Surrogate
-- data classes are generated by extracting a patch from an
-- image and generating transformed samples from it.
--
-- LongCat: Catherine Olsson, Long Sha, Kevin Brown
--------------------------------------------------------------------
require 'torch'

-------------------------------------------------------------------
--
-- parse command line arguments
if not opt then
   print '==> processing options'
   cmd = torch.CmdLine()
   cmd:text()
   cmd:text('STL-10 Dataset Preprocessing')
   cmd:text()
   cmd:text('Options:')
   cmd:option('-save', 'results', 'subdirectory to save/log/load experiments in')
   cmd:option('-type', 'double', 'type: double | float | cuda')
   cmd:text()
   opt = cmd:parse(arg or {})
end

-------------------------------------------------------------------


modelname='model_sur.net'
filename = paths.concat(opt.save, modelname)
surmodel = torch.load(filename)
convertModel = nn.Sequential()
convertModel:add(surmodel:get(1)) --conv
convertModel:add(surmodel:get(2)) --relu
convertModel:add(surmodel:get(3)) --maxpool
convertModel:add(surmodel:get(4)) --conv
convertModel:add(surmodel:get(5)) --relu
convertModel:add(surmodel:get(6)) --maxpool
convertModel:add(surmodel:get(7)) --view
convertModel:add(surmodel:get(8)) --dropout--this is neglected when :evaluate()
convertModel:add(surmodel:get(9)) --linear
convertModel:add(surmodel:get(10)) --relu

convertModel:evaluate()

inputN=3 --nfeats
inputW=96
inputH=96

patchW=32
patchH=32

outputM=128--states[3]
outputW=inputW-patchW+1
outputH=inputH-patchH+1

newTrain = {data=torch.Tensor(trsize,outputM,outputW,outputH),
            labels=trainData.labels,
            size = function() return trsize end
           }
newTest = {data=torch.Tensor(tesize,outputM,outputW,outputH),
            labels=testData.labels,
            size = function() return tesize end
          }

for k=1,trsize do
    for i=1,outputW do
        for j=1,outputH do
            local sample = trainData.data[{k,{},{i,i+patchW-1},{j,j+patchH-1}}]
            if opt.type == 'double' then sample = sample:double()
            elseif opt.type == 'cuda' then sample = sample:cuda() end
            outsample=convertModel:forward(sample)
            --if ran cuda on model, convert cuda back to double
            newTrain.data[{k,{},i,j}] = outsample:double()
        end
    end
end

for k=1,tesize do
    for i=1,outputW do
        for j=1,outputH do
            local sample = testData.data[{k,{},{i,i+patchW-1},{j,j+patchH-1}}]
            if opt.type == 'double' then sample = sample:double()
            elseif opt.type == 'cuda' then sample = sample:cuda() end
            outsample=convertModel:forward(sample)
            --if ran cuda on model, convert cuda back to double
            newTest.data[{k,{},i,j}] = outsample:double()
        end
    end
end

-- overwrite current trainData and testData
print '==> overwrite current trainData and testData'
trainData=newTrain
testData=newTest
--filename = paths.concat(opt.save, 'newTrain.dat')
--torch.save(filename, trainData,'ascii')
--filename = paths.concat(opt.save, 'newTest.dat')
--torch.save(filename, testData,'ascii')

-- construct a simple model for supervised learning
print '==>constructing simple linear model for supervised learning'
model = nn.Sequential()
--CHANGE P, CHANGE POOL SIZE TO BECOME 1/2
model:add(nn.SpatialMaxPooling(torch.floor(outputW/2),torch.floor(outputH/2),torch.floor(outputW/2),torch.floor(outputH/2)))
model:add(nn.Reshape(outputM*2*2))
model:add(nn.Linear(outputM*2*2,10))
