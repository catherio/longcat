
-------------------------------------------------------------------
-- Generate feature map
--
-- This script creates new train and test data set so they become
-- feature maps, which are the output of the model trained on surrogate
-- dataset, applied on each patch.
-- The model model_sur.net should be already trained by surrogate dataset
-- Based on the techniques in Dosovitskiy et al. Surrogate
-- data classes are generated by extracting a patch from an
-- image and generating transformed samples from it.
--
-- LongCat: Catherine Olsson, Long Sha, Kevin Brown
--------------------------------------------------------------------
require 'torch'

-------------------------------------------------------------------
--
-- parse command line arguments
if not opt then
   print '==> processing options'
   cmd = torch.CmdLine()
   cmd:text()
   cmd:text('STL-10 Dataset Preprocessing')
   cmd:text()
   cmd:text('Options:')
   cmd:option('-save', 'results', 'subdirectory to save/log/load experiments in')
   cmd:option('-type', 'double', 'type: double | float | cuda')
   cmd:text()
   opt = cmd:parse(arg or {})
end

-------------------------------------------------------------------
inputN=3 --nfeats
inputW=96
inputH=96

patchW=32
patchH=32

outputM=128--states[3]
outputW=inputW-patchW+1
outputH=inputH-patchH+1
-------------------------------------------------------------------

modelname='model_sur.net'
filename = paths.concat(opt.save, modelname)
surmodel = torch.load(filename)
convertModel = nn.Sequential()
-- add this convolution layer to add the model on top of 96*96 images
--convertModel:add(nn.SpatialConvolutionMM(inputN,inputN, patchW, patchH, 8, 8, 0))
convertModel:add(surmodel:get(1)) --conv
convertModel:add(surmodel:get(2)) --relu
convertModel:add(surmodel:get(3)) --maxpool
convertModel:add(surmodel:get(4)) --conv
convertModel:add(surmodel:get(5)) --relu
convertModel:add(surmodel:get(6)) --maxpool
convertModel:add(surmodel:get(7)) --view
convertModel:add(surmodel:get(8)) --dropout--this is neglected when :evaluate()
convertModel:add(surmodel:get(9)) --linear
convertModel:add(surmodel:get(10)) --relu

convertModel:evaluate()


step=8
newTrain = {data=torch.Tensor(trsize,outputM,math.ceil(outputW/step),math.ceil(outputH/step)),
            labels=trainData.labels,
            size = function() return trsize end
           }
newTest = {data=torch.Tensor(tesize,outputM,math.ceil(outputW/step),math.ceil(outputH/step)),
            labels=testData.labels,
            size = function() return tesize end
          }


for k=1,trsize do
    row=0
    for i=1,outputW,step do
        row=row+1
        local time = sys.clock()
        col=0
        for j=1,outputH,step do
            col=col+1
            local sample = trainData.data[{k,{},{i,i+patchW-1},{j,j+patchH-1}}]
            if opt.type == 'double' then sample = sample:double()
            elseif opt.type == 'cuda' then sample = sample:cuda() end
            outsample=convertModel:forward(sample)
            --if ran cuda on model, convert cuda back to double
            newTrain.data[{k,{},row,col}] = outsample:double()
        end

        timeSoFar = sys.clock() - time
        print("==> interim time to forward "..col.." patches is "..
             (os.date("!%X",timeSoFar)))
        estimate = timeSoFar * math.ceil(outputW/step)*trsize
        print("    estimated time to forward "..math.ceil(outputH/step)*math.ceil(outputW/step)*trsize.." patch is "..
             (os.date("!%X",estimate)))
    end
end

for k=1,tesize do
    row=0
    for i=1,outputW,step do
        row=row+1
        local time = sys.clock()
        col=0
        for j=1,outputH,step do
            col=col+1
            local sample = testData.data[{k,{},{i,i+patchW-1},{j,j+patchH-1}}]
            if opt.type == 'double' then sample = sample:double()
            elseif opt.type == 'cuda' then sample = sample:cuda() end
            outsample=convertModel:forward(sample)
            --if ran cuda on model, convert cuda back to double
            newTest.data[{k,{},row,col}] = outsample:double()
        end
        timeSoFar = sys.clock() - time
        print("==> interim time to forward "..col.." patches is "..
             (os.date("!%X",timeSoFar)))
        estimate = timeSoFar * math.ceil(outputW/step)*tesize
        print("    estimated time to forward "..math.ceil(outputH/step)*math.ceil(outputW/step)*trsize.." patch is "..
             (os.date("!%X",estimate)))
    end
end

-- overwrite current trainData and testData
print '==> overwrite current trainData and testData'
trainData=newTrain
testData=newTest
--filename = paths.concat(opt.save, 'newTrain.dat')
--torch.save(filename, trainData,'ascii')
--filename = paths.concat(opt.save, 'newTest.dat')
--torch.save(filename, testData,'ascii')

-- construct a simple model for supervised learning
print '==>constructing simple linear model for supervised learning'
model = nn.Sequential()
--CHANGE P, CHANGE POOL SIZE TO BECOME 1/2
model:add(nn.SpatialMaxPooling(torch.floor(math.ceil(outputW/step)/2),torch.floor(math.ceil(outputH/step)/2),torch.floor(math.ceil(outputW/step)/2),torch.floor(math.ceil(outputH/step)/2)))
model:add(nn.Reshape(outputM*2*2))
model:add(nn.Linear(outputM*2*2,10))
